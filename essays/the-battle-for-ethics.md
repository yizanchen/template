---
layout: essay
type: essay
title: The battle for Ethics
date: 2017-11-30
labels:
  - Ethics
  - Learning
---


Ethics is an important part of today's society because it is what keeps a society together. Ethics is needed in every profession, this is especially important to software engineering. I agree that software engineer can affect the public directly with little work and time compared to other professions. Software engineers will very often have to deal with personal information and it is a very serious problem if such information is unprotected or used for self-benefits. The very baseline of ethics means not to cause harm to stakeholders but this could be hard to achieve sometimes due to the limited information. In the context of software engineering, the stakeholders are hard to control due to the easy access to the Internet. Your target audiences and actual audiences can change over time. There are simply too much to consider that could cause potential ethics issue which will make simple tasks undoable. 


In "Case study: Autonomous cars", the ethics issue is what decision should autonomous cars make in unavoidable casualty accident.  The dilemma can be simplified into three choices, protect the passengers at all cost, minimize casualty even if it would cost the life of the passengers and minimize casualty with a priority to the passengers' life. Survey result show people wish to see autonomous cars programmed to minimize casualty even if it would cost the life of the passengers. But they questioned it would get implemented and they don't want to own such autonomous cars because nobody would want to buy a car that will sacrifice itself. 


It is very hard to take an ethical stance in this dilemma. The true purpose of this dilemma is not to find the best answer because they are simply too many holes in the situation. Softwares are much faster than human and they can scan the surrounding environment to make the best decision minizine casualty. But the best thing to do is to avoid this situation, so the program doesn't have to make decisions. The true purpose of this dilemma is to question who should be at fault if machines are faced with ethical situations and result in ethical debates. I don't think there is an absolute answer to this, but rather should be investigated like any human case. There is already a robot with citizenship in our world and such ethical questions would only appear more. 
